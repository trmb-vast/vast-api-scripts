#!/bin/bash
#
#  Vast metrics API scraper
#  This is called from the vast-metrics-cron every 5 minutes
#  it will pull the previous 10 minutes of metrics, and thus fill any holes.
#  feel free to run it at 1 minute intervals via cron, like this:
#* * * * * /opt/opsmon/API/get-vast-metrics -p $HOME/.ssh/vms_creds  \
#     -r 1 -r 2 -r 3 -r 4 -r 5 -r 8 -r 9 -r 15 -c se-202 -v 10.61.10.202 -g 10.61.201.12

#  Author:  rob@vastdata.com
#  Fri Sep  6 12:34:55 PDT 2019  rmallory .. adapted from metrics scraper.
#  Wed 11 Aug 2021 02:53:48 AM UTC rmallory .. fit to new api format
#  Sun 15 Aug 2021 11:34:02 PM UTC rmallory .. refactored for multi-cnodes
#  Mon 30 Aug 2021 07:32:17 PM UTC rmallory .. removed python dependency.. fixed DONTSEND flag
#
# Notes: newer versions at:  https://github.com/trmb-vast/api-tools
# dependencies: jshon   http://kmkeen.com/jshon/  (use my build_jshon script)
#               netcat "yum install netcat"
#               curl   "yum install curl"
#               graphite server somewhere  (or use -the -D flag)
#               python - for pretty printing -processing json .. no longer needed

installdir=$(
	cd $(dirname $0)
	pwd
)
PATH=/bin:/usr/bin:/usr/sbin:$installdir
HOST=$(uname -n)

NC="$(which nc) -w1" #some versions of netcat work better with -w1 arg.
NC="$(which nc) -w0" #some versions of netcat work quicker with -w0 arg.

####### Fill out your variables here
VMS=10.61.10.201 #IP of Vast management server
VMSUSER=admin
VMSPASS=xxx # change this or better yet use the -p flag below

# symlink to this script with the cluster name as last _field
# and it will auto-set the cluster... alternative to -c <cluster>
CLUSTER=$(echo $0 | awk -F_ '{print $NF}')
CLUSTER=${CLUSTER:-VastOne}
echo CLUSTER: $CLUSTER

### if you don't want to use the -g <graphitehost> flag, then set here
GRAPHITE_HOST=10.61.201.12 #IP of Graphite host
GRAPHITE_PORT=2003         #Graphite listener port


usage() {
	echo "Usage: $0 -p <credentialfile> -g <graphite host> -c <cluster> -v <vms name/ip>  "
	echo "     a script to retreive JSON metrics from the VAST API and push to Graphite"
	echo " the required -r <report>  is the VAST metric ID. ..multiple -r <report> are fine."
	echo "-p <credentialfile> is a file with user:pass  of vms user to run queries as. chmod go-rwx it as needed"
	echo "use the -D flag to prevent sending to the -g Graphite host. or dont pass -g "
}

DONTSEND=false
DEBUG=${DEBUG:-false}

while getopts r:p:c:g:v:r:d:Dh c; do
	case "$c" in
	p) CREDS_FILE="${OPTARG}" ;;
	g) GRAPHITE_HOST="${OPTARG}" ;;
	c) CLUSTER="${OPTARG}" ;;
	r)
		if [ -n "${OPTARG}" ]; then
			REPORTS="${REPORTS} ${OPTARG}"
		else
			end_die "Invalid report list supplied"
		fi
		;;
	v) VMS="${OPTARG}" ;;
	d) DEBUG=true ;;
	D) DONTSEND=true ;;
	h | \?)
		usage
		exit 1
		;;
	esac
done
shift $((${OPTIND} - 1))

### reading credentials from a file (readable by this user, or with SUDO)
### is more safe than embedding passwords in scripts, or passing as args
if [ -f $CREDS_FILE ]; then
	VMSUSER=$(cat $CREDS_FILE | cut -d: -f1)
	VMSPASS=$(cat $CREDS_FILE | cut -d: -f2)
fi

if [ "x" = "x${REPORTS}" ]; then
	echo " -r <report> argument is required..."
	exit
fi

if [ "x" = "x${GRAPHITE_HOST}" ]; then
	DONTSEND=true
fi

####
# Each curl/report goes to a different named file in /tmp
JSON=/tmp/vmsdata_${CLUSTER}_$(echo $1 | tr ' ' '_').json
rm -f $JSON
####

## Actually, these days we set NOW from the timestamp in the json file
[[ $(uname -s) = "Linux" ]] && NOW=$(date +%s)

### We don't yet use this function.. 
### since we store the metrics into our TSDB with the "FQN" name.. 
### ... This function is used for a "create grafana dashboard" script.
### What does it do?  It dlwonloads the list of metrics which includes FQN (internal name) and Title (long name)
get_metric_names() {
	#  Update our local /tmp/xxx_metrics cache file every 720 hours
	if [ -n "$(find ${JSON}_metrics -mtime +720)" ]; then
		echo "...Calling VAST API to Criss-Cross Metric names"
		rm -f ${JSON}_metrics
		curl -u ${VMSUSER}:${VMSPASS} -H "accept: application/json" --insecure -X GET "https://$VMS/api/metrics/"  >${JSON}_metrics
		### this is the main function, caller per report

		METRICS_NUM=$($installdir/jshon -l <${JSON}_metrics | tr '\n' ' ')
		for i in $(seq 1 $METRICS_NUM); do
			METRIC_TITLE[$i]=$($installdir/jshon -e $i -e title <${JSON}_metrics | sed 's/"//g' | awk -F= '{print $NF}' | tr ',' '.')
			METRIC_FQN[$i]=$($installdir/jshon -e $i -e fqn <${JSON}_metrics | sed 's/"//g' | awk -F= '{print $NF}' | tr ',' '.')
			echo "METRIC_TITLE/FQN:${METRIC_TITLE[$i]}  = ${METRIC_FQN[$i]}"
		done
	fi

}
#get_metric_names

scrape_and_send_report() {

	#$DEBUG && set -x

	echo "...Calling VAST API for report $1 with curl"
	#curl -u ${VMSUSER}:${VMSPASS} -H "accept: application/json" --insecure -X GET "https://$VMS/api/monitors/${1}/query/?granularity=seconds&amp;aggregation=avg&amp;format_data=true" | python3 -m json.tool >$JSON
	#curl -u ${VMSUSER}:${VMSPASS} -H "accept: application/json" --insecure -X GET "https://$VMS/api/monitors/${1}/query/?granularity=seconds&amp;aggregation=avg&amp;format_data=true" >$JSON
	$DEBUG && echo "Setting time_frame=75s   .. this will return only the last 75 seconds of values.. "
	$DEBUG %% echo "(the extra 15 seconds s to cover holes in a previous iteration which might have a couple missing values) this is good if you run it once per minute"
	$DEBUG && echo "if you want to run once every 5 minutes, then read the code and flip the commented/uncommened lines."
	if [ -n "$(find $JSON -mtime +2 2>/dev/null)" ]  ; then  echo "$JSON file found to be more than 2 minutes old.. if you are sampling every 5 mins, read the code in $0" ; fi
	$DEBUG && set -x
	curl -u ${VMSUSER}:${VMSPASS} -H "accept: application/json" --insecure -X GET "https://$VMS/api/monitors/${1}/query/?granularity=seconds&amp;time_frame=75s&amp;aggregation=avg&amp;format_data=true" >$JSON
	#curl -u ${VMSUSER}:${VMSPASS} -H "accept: application/json" --insecure -X GET "https://$VMS/api/monitors/${1}/query/?granularity=minutes&amp;time_frame=20m&amp;aggregation=avg&amp;format_data=true" >$JSON    ### If you run a cron every 5 minutes, and want to collect 5 minute granularity samples, then use this and comment out the previous one. 
	$DEBUG && set +x

	NUMELEMENTS="$($installdir/jshon -l <$JSON)"
	#NUMELEMENTS=$((NUMELEMENTS-1)) ## we used to do this when we ignored timestamp
	echo NUMELEMENTS=$NUMELEMENTS

	#### This pulls out the preperty list..
	PROP_LIST_NUM=$($installdir/jshon -e prop_list -l <$JSON | tr '\n' ' ')
	for i in $(seq 1 $PROP_LIST_NUM); do
		ELE_NAME[$i]=$($installdir/jshon -e prop_list -e $i <$JSON | sed 's/"//g' | awk -F= '{print $NF}' | tr ',' '.')
	done

	#### This just checks if object_id changed.. eg, some reports are by cnode
	for SEQ in $(seq 1 3); do
		THIS=$($installdir/jshon -e data -e $SEQ -e 1 <$JSON)
		if [ "$THIS" = "$PREV" ]; then
			$DEBUG && echo "No change.. same object_id"
			MULTI_OBJECT_ID=false
		else
			$DEBUG && echo "object_id changed between samples.."
			MULTI_OBJECT_ID=true
		fi
		$DEBUG && echo PREV THIS $PREV $THIS
		PREV=$THIS
	done

	for x in $(#  should be 60 samples  or 10 minutes at 10 second interval
		seq 1 $($installdir/jshon -e data -l <$JSON)
	); do
		for i in $(seq 1 $PROP_LIST_NUM); do
			if [ ${ELE_NAME[$i]} = "timestamp" ]; then
				# convert to epochtime:   date -d "2019-07-02T02:24:38Z" +%s
				TIMESTAMP=$($installdir/jshon -e data -e $x -e 0 <$JSON)
				TIMESTAMP=$(echo $TIMESTAMP | sed 's/"//g')
				NOW=$(/usr/bin/date -d "$TIMESTAMP" +%s)
			fi

			if [ ${ELE_NAME[$i]} = "object_id" ]; then
				OBJID=$($installdir/jshon -e data -e $x -e $i <$JSON)
				$DEBUG && echo OBJID=$OBJID
			fi

			VAL[$i]=$($installdir/jshon -e data -e $x -e $i <$JSON | sed 's/"//g' | tr ',' '.')

			# Next line will skip entries named timestamp or object_id
			if [ -n "$(echo ${ELE_NAME[$i]} | egrep -v 'timestamp|object_id')" ]; then
				if [ "$MULTI_OBJECT_ID" = "true" ]; then
					echo vast.${CLUSTER}.cnode-${OBJID}.${ELE_NAME[$i]} ${VAL[$i]} $NOW
					$DONTSEND || echo vast.${CLUSTER}.cnode-${OBJID}.${ELE_NAME[$i]} ${VAL[$i]} $NOW | $NC $GRAPHITE_HOST ${GRAPHITE_PORT}
				else
					echo vast.${CLUSTER}.${ELE_NAME[$i]} ${VAL[$i]} $NOW
					$DONTSEND || echo vast.${CLUSTER}.${ELE_NAME[$i]} ${VAL[$i]} $NOW | $NC $GRAPHITE_HOST ${GRAPHITE_PORT}
				fi
			fi
		done
		$DEBUG && echo x is now $x
	done

}

for i in $REPORTS; do
	scrape_and_send_report $i
done
